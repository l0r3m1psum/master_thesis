\documentclass{article}

\begin{document}
\makeindex

\section{Neural Networks}
\subsection{Optimization}
Requires gradient of the loss.
\section{Automatic Differentiation}
% Here I should put matrix calculus.
\subsection{Reverse Mode}
Since we only care about gradient of scalar valued functions it is called
back-propagation. What we do is not strictly ``automatic differentiation'' but
still.
\section{Hardware Accellerators}
\subsection{GPU architecture}
\section{Speed-up Neural Networks (Training & Inference)}
There are various ways in thich this can be done.Here we put the litterature
review. Algorithmic (FF vs conv), Numeric optimization, Hardware utilization,
compilation etc\dots
\end{document}
